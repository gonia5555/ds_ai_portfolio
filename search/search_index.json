{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home Page","text":"\ud83d\udc4b Welcome! <p>       My name is Ma\u0142gorzata Osm\u0119da.       I am a Polish professional who has been living in Spain for the past 18 years.       Although I spent most of my professional life working in the tourism industry,       at the beginning of 2025 I encountered data analysis for the first time.       This field quickly captured my attention and turned into a true passion.     </p> <p>       Since then, I have been working every day to expand my knowledge and strengthen my analytical and technical skills,       driven by curiosity, persistence, and a strong motivation to grow in the data field, with a particular focus on       data analysis, machine learning, and artificial intelligence.     </p> <p>   This website showcases selected projects I have been working on recently, highlighting my   analytical approach, problem-solving mindset, and practical use of data science tools and models. </p> <p>   This portfolio was created with the goal of landing my first role in a data-related position.      Feel free to explore the projects! </p>"},{"location":"AI%20receipe%20generator/","title":"\ud83c\udf7d\ufe0f AI Recipe Generator","text":""},{"location":"AI%20receipe%20generator/#project-overview","title":"Project Overview","text":"<p>AI Recipe Generator is a web application built with Streamlit that uses artificial intelligence to generate personalized recipes based on either a photo of ingredients or a manually entered list of products.</p> <p>The application combines computer vision, OpenAI language models, and a vector database (Qdrant) to deliver practical, real-world AI functionality in an intuitive user interface.</p>"},{"location":"AI%20receipe%20generator/#openai-api-key-required","title":"\ud83d\udd11 OpenAI API Key Required","text":"<p>To use the application, an OpenAI API Key is required.</p> <ul> <li>The API key must be entered in the sidebar input field inside the application.</li> <li>The application will not run until a valid API key is provided.</li> <li>The API key is not stored permanently and is used only for the current session.</li> </ul> <p>\ud83d\udc49 Live application: here.</p>"},{"location":"AI%20receipe%20generator/#key-features","title":"Key Features","text":"<ul> <li> <p>\ud83d\udcf8 Recipe generation from images   Automatically detects ingredients from a photo and generates a matching recipe.</p> </li> <li> <p>\ud83d\udcdd Recipe generation from text input   Users can enter ingredients manually, separated by commas.</p> </li> <li> <p>\ud83c\udf0d Multilingual support   The application supports three languages:</p> </li> <li>English  </li> <li>Polish  </li> <li> <p>Spanish  </p> </li> <li> <p>\ud83c\udf70 Recipe type selection </p> </li> <li>Sweet  </li> <li> <p>Savory  </p> </li> <li> <p>\ud83d\udcbe Recipe saving   Users can save up to 10 recipes per session.</p> </li> <li> <p>\ud83d\udcc4 PDF export   Each recipe can be downloaded as a PDF file with full Unicode support.</p> </li> <li> <p>\ud83e\udde0 AI-powered content generation   Recipes are generated using OpenAI models and text embeddings.</p> </li> </ul>"},{"location":"AI%20receipe%20generator/#technologies-used","title":"Technologies Used","text":"<ul> <li>Python</li> <li>Streamlit</li> <li>OpenAI API (GPT models &amp; embeddings)</li> <li>Qdrant (vector database)</li> <li>Pillow (image processing)</li> <li>ReportLab (PDF generation)</li> <li>dotenv (environment variable management)</li> </ul>"},{"location":"AI%20receipe%20generator/#project-purpose","title":"Project Purpose","text":"<p>The goal of this project was to build a complete, production-ready AI application that demonstrates: - integration of large language models, - image-based input processing, - vector database usage, - clean UI/UX design, - real-world applicability.</p> <p>This project serves as a portfolio example of an end-to-end AI solution, from user interface to backend AI services.</p>"},{"location":"AI%20receipe%20generator/#author","title":"Author","text":"<p>Ma\u0142gorzata Osm\u0119da Data Science &amp; AI Enthusiast</p>"},{"location":"Community%20matching%20application/","title":"Community Matching App \u2013 Machine Learning Project","text":""},{"location":"Community%20matching%20application/#project-overview","title":"Project Overview","text":"<p>This project is an interactive community matching application built using Streamlit and machine learning techniques. The goal of the application is to match users with a group of people who share similar preferences and characteristics, based on survey data.</p> <p>The app analyzes user input such as age group, education level, favorite animals, preferred places, and gender, and assigns the user to the most relevant cluster using a trained clustering model.</p> <p>\ud83d\udc49 Live application: here.</p>"},{"location":"Community%20matching%20application/#how-it-works","title":"How It Works","text":"<ol> <li>The user fills out a short survey via the sidebar interface.</li> <li>The input data is processed and passed to a pre-trained clustering model (PyCaret).</li> <li>The model assigns the user to a specific cluster representing a group of similar individuals.</li> <li>The application displays:</li> <li>the user\u2019s matching group,</li> <li>a descriptive profile of the cluster,</li> <li>a match score,</li> <li>visualizations showing distributions of key features within the group,</li> <li>example participants from the same cluster.</li> </ol> <p>The application supports two languages (Polish and English).</p>"},{"location":"Community%20matching%20application/#data","title":"Data","text":"<p>The dataset used in this project consists of survey responses collected from participants of a Data Science course. The data includes categorical and demographic features such as:</p> <ul> <li>age group  </li> <li>education level  </li> <li>favorite animals  </li> <li>favorite places  </li> <li>gender  </li> </ul> <p>All data was used strictly for educational and portfolio purposes.</p>"},{"location":"Community%20matching%20application/#technologies-used","title":"Technologies Used","text":"<ul> <li>Python</li> <li>Streamlit \u2013 interactive web application</li> <li>PyCaret (Clustering) \u2013 machine learning pipeline</li> <li>Pandas / NumPy \u2013 data processing</li> <li>Plotly \u2013 interactive visualizations</li> <li>Qdrant \u2013 vector database</li> <li>OpenAI Embeddings API \u2013 text embeddings</li> <li>dotenv / Streamlit Secrets \u2013 environment and credentials management</li> </ul>"},{"location":"Community%20matching%20application/#key-features","title":"Key Features","text":"<ul> <li>Machine learning\u2013based user clustering</li> <li>Interactive UI with real-time predictions</li> <li>Multilingual support (PL / EN)</li> <li>Data visualizations for cluster analysis</li> <li>Modular and scalable application structure</li> </ul>"},{"location":"Community%20matching%20application/#purpose-of-the-project","title":"Purpose of the Project","text":"<p>This project was created as part of my Data Science learning journey to demonstrate practical skills in:</p> <ul> <li>exploratory data analysis,</li> <li>machine learning model deployment,</li> <li>building end-to-end data applications,</li> <li>integrating external APIs and vector databases.</li> </ul> <p>It serves as a portfolio project showcasing applied data science and AI engineering skills.</p>"},{"location":"Community%20matching%20application/#author","title":"Author","text":"<p>Ma\u0142gorzata Osm\u0119da Data Science &amp; AI Enthusiast</p>"},{"location":"Half%20Marathon%20Time%20Predictor/","title":"\ud83c\udfc3 Half Marathon Time Predictor","text":""},{"location":"Half%20Marathon%20Time%20Predictor/#project-overview","title":"Project Overview","text":"<p>Half Marathon Time Predictor is an AI-powered web application that estimates a runner\u2019s half marathon (21.097 km) finish time based on natural language input.</p> <p>Instead of filling out structured forms, users simply describe themselves in plain English (or Polish), and the application automatically extracts key features using a Large Language Model (LLM). These features are then passed to a trained Machine Learning model to generate a realistic race-time prediction.</p> <p>\ud83d\udc49 Live application: here.</p>"},{"location":"Half%20Marathon%20Time%20Predictor/#how-it-works","title":"How It Works","text":"<ol> <li>The user describes themselves in natural language    (age, gender, and 5 km race time).</li> <li>An OpenAI LLM extracts structured data from the text.</li> <li>The extracted data is validated and preprocessed.</li> <li>A Machine Learning regression model predicts the half marathon finish time.</li> <li>Results are visualized and compared against other runners.</li> </ol>"},{"location":"Half%20Marathon%20Time%20Predictor/#key-features","title":"Key Features","text":"<ul> <li> <p>\ud83d\udcdd Natural language input   No forms required \u2014 the app understands free-text descriptions.</p> </li> <li> <p>\ud83e\udde0 LLM-powered data extraction   OpenAI models extract age, gender, and 5 km time directly from text.</p> </li> <li> <p>\ud83e\udd16 Machine Learning prediction   A trained regression model estimates half marathon performance.</p> </li> <li> <p>\ud83c\udf0d Multilingual support </p> </li> <li>English  </li> <li> <p>Polish  </p> </li> <li> <p>\ud83d\udcca Data visualization </p> </li> <li>5 km vs half marathon time comparison  </li> <li> <p>Histogram comparing the user\u2019s result with other runners  </p> </li> <li> <p>\ud83c\udfc6 Performance percentile   Shows how the predicted time compares to thousands of other runners.</p> </li> <li> <p>\ud83d\udd0d Observability with Langfuse   LLM calls are traced for monitoring, debugging, and experimentation.</p> </li> </ul>"},{"location":"Half%20Marathon%20Time%20Predictor/#data-used","title":"Data Used","text":"<p>The Machine Learning model was trained on real race data from:</p> <ul> <li>Half Marathon Wroc\u0142aw 2023</li> <li>Half Marathon Wroc\u0142aw 2024</li> </ul> <p>This ensures that predictions are grounded in real-world performance distributions rather than synthetic data.</p>"},{"location":"Half%20Marathon%20Time%20Predictor/#technologies-used","title":"Technologies Used","text":"<ul> <li>Python</li> <li>Streamlit</li> <li>Scikit-learn</li> <li>OpenAI API (GPT models)</li> <li>Langfuse (LLM observability)</li> <li>Pandas &amp; NumPy</li> <li>Matplotlib</li> <li>Joblib</li> <li>DigitalOcean (deployment)</li> </ul>"},{"location":"Half%20Marathon%20Time%20Predictor/#project-goal","title":"Project Goal","text":"<p>The goal of this project was to demonstrate:</p> <ul> <li>practical use of LLMs for structured data extraction,  </li> <li>integration of Machine Learning models with LLM pipelines,  </li> <li>explainable and user-friendly AI applications,  </li> <li>real-world performance prediction based on authentic datasets.</li> </ul> <p>This application serves as a portfolio-grade example of combining NLP, Machine Learning, and modern AI tooling in a single production-ready system.</p>"},{"location":"Half%20Marathon%20Time%20Predictor/#author","title":"Author","text":"<p>Ma\u0142gorzata Osm\u0119da Data Science &amp; AI Enthusiast</p>"},{"location":"iris/","title":"Iris","text":""},{"location":"iris/#exploratory-data-analysis-eda-iris-dataset","title":"\ud83c\udf38 Exploratory Data Analysis (EDA) \u2013 Iris Dataset","text":"<p>In this project, I invite you to explore the world of exploratory data analysis (EDA) using one of the most iconic datasets in data science \u2014 the Iris dataset. This analysis goes beyond numbers, serving as a practical exercise in analytical thinking and data-driven insight generation.</p> <p>The project focuses on uncovering the structure of the data and relationships between flower features, demonstrating how data can tell a meaningful story. Through descriptive statistics and visualizations, I examine differences between iris species and identify the features that best distinguish them.</p> <p>This analysis provides a strong starting point for further data work \u2014 especially in the context of classification, modeling, and machine learning \u2014 and reflects my mindset as a Junior Data Analyst / Junior Data Scientist: curiosity, attention to detail, and the ability to translate data into clear, actionable insights.</p> <p> Download Notebook (HTML) </p> <p></p>"},{"location":"titanic/","title":"Titanic","text":""},{"location":"titanic/#exploratory-data-analysis-eda-titanic-dataset","title":"\ud83d\udea2 Exploratory Data Analysis (EDA) \u2013 Titanic Dataset","text":"<p>In this project, I explore the world of exploratory data analysis (EDA) using the well-known Titanic dataset. This analysis goes beyond basic statistics and serves as a practical exercise in analytical thinking and drawing meaningful conclusions from data.</p> <p>The project focuses on understanding the structure of the dataset and uncovering relationships between passenger characteristics and survival outcomes. Through descriptive statistics and visualizations, I analyze how factors such as age, gender, passenger class influenced survival rates.</p> <p>This analysis provides a strong foundation for further data work \u2014 particularly in the context of classification, predictive modeling, and machine learning \u2014 and reflects my mindset as a Junior Data Analyst / Junior Data Scientist: curiosity, attention to detail, and the ability to translate data into clear, actionable insights.</p> <p>Pobierz Notebook</p> <p></p>"}]}